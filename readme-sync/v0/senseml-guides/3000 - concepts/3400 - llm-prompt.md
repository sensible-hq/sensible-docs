---
title: "LLM prompt configuration"
hidden: true
---

You can configure the prompt that Sensible provides to a large-language model (LLM) to fine tune your results. You can configure some aspects of the prompt, such as the context description, for all fields in a config, and for others, you can configure them at the field level.

See the following image for an example of configuring a field that uses the [Query](doc:question) method. 



TODO: so if you have "i don't know" -> system returns null. otherwise, you'll get `hippo` back. Goes in the NLP preprocessor



TODO: another resource from dru on prompts



page hinting: yeah strips it out.

![Click to enlarge](https://raw.githubusercontent.com/sensible-hq/sensible-docs/main/readme-sync/assets/v0/images/final/llm_prompt.png)
